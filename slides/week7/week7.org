#+TITLE: Week 7
#+AUTHOR: Evan Bretl (borrowing from RJ ROS Training)
#+EMAIL: ebretl3@gatech.edu

* What are we doing today?
- Controls
  - PID
- AI
  - Computer vision
  - Machine learning
    - Neural networks
      - Convolutional neural networks

* Controls
- We have a system with state =A= and a desired state =B=
  - The desired state is also called the _setpoint_
- At every timestep, we give our system a control input
- Example
  - state = speed of a spinning wheel
  - control input = proportion of time that the motor is turned on (PWM)
- How can we reliably get from A to B?

* Open-loop control
- In open-loop, we don't know our state
- Guess what you need to do to reach state =B=
#+BEGIN_SRC
Algorithm OpenLoop:
  while 1:
    get new setpoint B
    control_input = some_function_of(B)
#+END_SRC

* bang-bang control
- Open-loop is usually not good enough (conditions vary over time)
- Let us now have a sensor which gives our current state =A=
- Now we know our state's _error_, or difference from the setpoint
- Unless we are very close to the setpoint, move towards the setpoint with a constant contol input
#+BEGIN_SRC
Algorithm BangBang:
  while 1:
    measure state A
    get new setpoint B
    error = B - A
    if error > 0.1:
      control_input = 100
    else if error < -0.1:
      control_input = -100
#+END_SRC

* Proportional control
- Bang-bang control is not smooth
- What if we scale our control input linearly with our error?
  - This is the proportional gain P
#+BEGIN_SRC
Algorithm ProportionalControl:
  while 1:
    measure state A
    get new setpoint B
    error = B - A
    control_input = P * error
#+END_SRC

* PID control
- PID = proportional, integral, derivative
- Proportional control sometimes has a _steady-state error_
  - e.g. some force is required to maintain a position
  - Introduce an integral gain =I= which accumulates error over time
- P + I control can reach the setpoint, but can overshoot and oscillate
  - Introduce a derivative gain =D= which counteracts fast changes in the error

* PID control
- [[https://www.researchgate.net/profile/Vishnu_Divakar/publication/281746636/figure/fig4/AS:284649973665803@1444877250888/Figure-5-PID-Equation.png]]
- [[https://upload.wikimedia.org/wikipedia/commons/3/33/PID_Compensation_Animated.gif]]

* PID in practice
- For many problems, =I= or =D= can be 0
- Integral term should only care about relatively recent errors, not ones from 10 minutes ago

#+BEGIN_SRC
Algorithm PIDControl:
  while 1:
    measure state A
    get new setpoint B
    error = B - A
    integral_error += error
    derror = (error - prev_error) / timestep_length
    control_input = (P * error) + (I * integral_error) + (D * derror)
#+END_SRC

* Artificial Intelligence
- Definition: computer systems able to perform tasks which normally require human intelligence
- Some sub-fields and areas of study
  - Vision
  - Planning
  - Machine Learning
  - Natural Language Processing (understanding sentences)
  - Speech to Text / Text to Speech
- Today we are looking at mostly Computer Vision, some Machine Learning, and a little interaction between the two

* Computer Vision
- Trying to answer: how can we make computers extract useful information from images?
- OpenCV (Open Source Computer Vision Library)
  - Industry standard for image processing
  - [[https://docs.opencv.org/3.4.3/d9/df8/tutorial_root.html][Online documentation]]

* Images
- An image is an array with rows and columns
- Each element of the array is a pixel in the image and its location in the array corresponds to its location in the image

* Color Types
- There are many different formats for an image
  - Grey scale
  - RGB
  - HSV

** Grey scale
- An image where each pixel is only white to black
- Range [0-255]
  - 255 is white
  - 0 is black

** Color Images
- Color images don't embed the color of a pixel in one element. Often, you'll
  find each pixel represented in BGR (Blue component, Green Component, Red
  Component) form. So now, each row of a color image is 3 times as long as a
  row of a black and white image.
- [[https://i.imgur.com/QlokNTv.png]]
- Images don't have to be stored in just BGR format!

** HSV Images
- Each Pixel in a color image has a hue, a saturation, and a luminosity.
- Even though our cameras read in images with RGB, converting them to HSV is
  easy with OpenCV
[[https://image.slidesharecdn.com/01presentationhuehistograms-150707215651-lva1-app6892/95/about-perception-and-hue-histograms-in-hsv-space-5-638.jpg]]

*** HSV explained
- Hue
  - The actual color (rotation on the color wheel)
- Saturation
  - Indicates the amount of color (grey is zero saturation)
- Value
  - How light the color is (black is zero, white is full)
#+ATTR_HTML: :width 30%
[[file:https://www.nmt.edu/tcc/help/pubs/colortheory/img/cone.png]]

*** Why do we use HSV
- HSV encodes image data in a way that is resistant to changes in color
- To put it another way, on a sunny day an image will contain more red, more
  blue, and more green than on a cloudy day. All three channels are affected
- On a sunny day, the saturation channel will be largely effected, but we can
  expect hue to remain mainly stable. This makes it easier to do searches for
  colors in the HSV space

* Computer vision: linear filtering
- A _kernel_ is a square matrix that an image is "multipled" by
- Input image is transformed to an output image
- Different kernels do different things. Examples:
  - Edge detection - output has high values where input is changing quickly
  - Noise reduction - smooths out "salt" or "pepper" noise
  - Feature extraction - output has high values when input looks a certain way
- Kernels are usually 3x3 to 7x7 matrices

* Applying filters: convolution
- In CV, _convolution_ is the process of applying a linear filter to the image
- Each pixel of the output is a weighted sum (w1*x1 + s2*x2 + w3*x3 + ...) of nearby pixels in the input
  - The weights (w1, w2, w3, ...) are elements in the kernel matrix
#+ATTR_HTML: :width 40%
[[https://www.cc.gatech.edu/~san37/img/dl/conv.gif]]

#+BEGIN_NOTES
for r from 0 to rows - 1 - kernel_size:
  for c from 0 to columns - 1 - kernel_size:
    accumulator = 0
    for kr from 0 to kernel_size:
      for kc from 0 to kernel_size:
        accumulator += input_image[r + kr][c + kc] * kernel[kr][kc]
    output_image[r][c] = accumulator
#+END_NOTES

** Identity
- Returns the original image
#+attr_latex: :mode math :environment matrix
| 0 | 0 | 0 |
| 0 | 1 | 0 |
| 0 | 0 | 0 |
[[file:https://i.imgur.com/YWH6NPC.png]]

** Blur
- used to reduce noise
#+attr_latex: :mode math :environment matrix
| 1/9 | 1/9 | 1/9 |
| 1/9 | 1/9 | 1/9 |
| 1/9 | 1/9 | 1/9 |
[[file:https://i.imgur.com/ogsHVT9.png]]

*** Gaussian blur
#+attr_latex: :mode math :environment matrix
| 1/16 | 1/8 | 1/16 |
| 1/8  | 1/4 | 1/8  |
| 1/16 | 1/8 | 1/16 |
[[file:https://i.imgur.com/l3lahuH.png]]

*** Gaussian blur larger
#+attr_latex: :mode math :environment matrix
| 1/256 | 1/64 | 3/128 | 1/64 | 1/256 |
| 1/64  | 1/16 | 3/32  | 1/16 | 1/64  |
| 3/128 | 3/32 | 9/64  | 3/32 | 3/128 |
| 1/64  | 1/16 | 3/32  | 1/16 | 1/64  |
| 1/256 | 1/64 | 3/128 | 1/64 | 1/256 |

** Edge Detection
- Gradients in images
  - Derivative (rate at which color is changing) in x and y directions
- Good to blur before using edge detection

*** Sobel
- Gradient calculation
  - First derivative in x and y directions
- Edge detection
- Uses two kernels and combines the results

*** Right Sobel
#+attr_latex: :mode math :environment matrix
| -1 | 0 | 1 |
| -2 | 0 | 2 |
| -1 | 0 | 1 |
[[file:https://i.imgur.com/n70YDco.png]]

*** Top Sobel
#+attr_latex: :mode math :environment matrix
|  1 |  2 |  1 |
|  0 |  0 |  0 |
| -1 | -2 | -1 |
[[file:https://i.imgur.com/0ag5YRp.png]]

*** Combination
[[file:https://i.imgur.com/zOUwHgY.png]]

*** Blurred Sobel
[[file:https://i.imgur.com/LapsYpb.png]]

*** Laplacian
#+attr_latex: :mode math :environment matrix
| 0 |  1 | 0 |
| 1 | -4 | 1 |
| 0 |  1 | 0 |
[[file:https://i.imgur.com/3nHT9Uz.png]]

*** Blurred Laplacian
[[file:https://i.imgur.com/1lRPNTa.png]]

* Canny Edge
- There are more advanced edge detection techniques, like Canny
- You can read about them on your own time
[[file:http://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_canny/py_canny.html][Canny Edge]]

* Hough Lines
- How to find lines in an image
- Step 1: compute edge detection for the image
- Step 2: Express a bunch of lines in (r, theta) polar format where r is the distance from pixel (0,0) and theta is the rotation of the line
- Step 3: (Voting) The best line is the (r, theta) which overlaps the most with the edge detection
[[file:https://docs.opencv.org/3.0-beta/doc/py_tutorials/py_imgproc/py_houghlines/py_houghlines.html][Hough Lines]]

** Hough Circles
- You can use a very similar strategy to find circles
  - [[file:https://docs.opencv.org/3.0-beta/doc/py_tutorials/py_imgproc/py_houghcircles/py_houghcircles.html][Hough Circles]]
- You could use this method for any shape, but it's most useful when you can specify the shape with only a few parameters (e.g. r and theta for lines)

* Machine Learning
- How can we get algorithms to improve themselves over time?
- Data driven
  - Define a model which can be configured in many different ways
  - Programmer specifies an optimization procedure
  - Model can then be "fit to" or "trained on" the data

* Types of ML
- Supervised learning (what we are talking about today)
  - Model predicts outputs based on inputs
  - Every "example" in the data has an input and a "label" which is what we want the model to output
- Reinforcement learning
  - Model tries to optimize its strategy at a task (maximize a reward function)
  - Data is generated via observation of the learning environment
- Unsupervised learning
  - Finding clusters and other patterns in unlabeled or poorly labeled data

* Supervised learning
- The goal is to fit a model to the training data set such that the model is useful for data which is not in the training set
  - This is called _generalization_
- Linear vs. nonlinear problems
  - [[https://leonardoaraujosantos.gitbooks.io/artificial-inteligence/content/more_images/linear_vs_nonlinear_problems.png]]

* Decision Tree Learning
- A decision tree is one way for computers to make decisions
  - Network of true/false comparisons on the input data
  - Basically playing "20 Questions" with your data
- Example: predicting if an individual on board the Titanic would have survived
  - sibsp = siblings present. ML cares about correllation, not causation
  - [[https://upload.wikimedia.org/wikipedia/commons/f/f3/CART_tree_titanic_survivors.png]]

* Decision Tree Learning
- Considerations for training
  - Maximize information gain: try to use conditions that are true around 50% of the time
  - Overfitting: keep the tree small and general so that it works with examples that aren't in the training data
    - e.g. In the Titanic prediction example, don't use people's names in your decision tree

* Logistic Regression
- Consider an input which is a vector (1-dimensional array) of numbers
- We want to learn how to guess the probability that something is true (e.g. surviving Titanic)
- Idea
  - 1. Take a linear combination (sum with weights) of the input elements and add a constant offset
  - 2. Pass this result into the sigmoid function
#+ATTR_HTML: :width 30%
[[https://i.imgur.com/KBfvHRI.png]]

* Logistic Regression
- The logistic regression model has N+1 parameters (weights in the linear combination) where N is the number of elements in the input vector. The +1 is the offset or bias
- Training (gradient descent)
  - Step 1: compute how far away the model is from being correct on all the training data (this is called the _loss_)
  - Step 2: for each parameter, add a tiny bit to it and recompute the loss. This gives you the derivative of the loss with respect to that parameter
  - Step 3: change each parameter up or down in proportion to that derivative

* SVM
- Support Vector Machine
- Kind of like logistic regression, but has more linear algebra theory
- Logistic regression is "linear" (because all our parameters are part of a linear combination), while SVM can do nonlinear problems
- You can read [[https://medium.com/machine-learning-101/chapter-2-svm-support-vector-machine-theory-f0812effc72][this article]] for a gentle introduction
- Wikipedia has a less gentle introduction to the topic

* Neural networks
- You can think of a logistic regression model like a neuron in the brain
  - Many receptors for its inputs
  - The effect of multiple receptors is additive
  - The neuron's output is activated if the input is above a certain threshold
    - This threshold is represented by the constant offset
    - The activation is represented by the sigmoid function in this case
#+ATTR_HTML: :width 40%
[[https://3c1703fe8d.site.internapcdn.net/newman/gfx/news/hires/2018/2-whyareneuron.jpg]]

* Neural Networks
- A neural network is like a composition of lots of neurons, each of which work like a linear regression model
- Organized in layers. Each layer has:
  - 1. An input vector, which is the output of the previous layer
  - 2. M linear combinations making M weighted sums from N inputs
  - 3. An activation function (doesn't have to be sigmoid) applied to each weighted sum. These M activations are the output
#+ATTR_HTML: :width 40%
[[http://cs231n.github.io/assets/nn1/neural_net2.jpeg]]

* Neural Networks
#+ATTR_HTML: :width 40%
[[http://cs231n.github.io/assets/nn1/neural_net2.jpeg]]
- The above network has 4*4 + 5*4 + 5*1 = 41 parameters
  - The constant offset parameter is like an extra input
- State-of-the-art neural networks are deeper (more layers), wider (more neurons per layer), and have millions of parameters

* Neural Networks
- Training works the same way as logistic regression (gradient descent)
  - Step 1: compute the loss on the training data
  - Step 2: for each parameter, add a tiny bit to it and recompute the loss. This gives you the derivative of the loss with respect to that parameter
  - Step 3: change each parameter up or down in proportion to that derivative

* Neural Networks
- Training deep neural networks is hard
  - Vanishing gradients: derivatives near the output are small, so the early layers don't learn anything
  - Exploding gradients: derivatives near the output are high, so updating the early layers is unstable
  - Computational cost is high
  - Time and manpower cost for labeling lots of training data is _very_ high

* Neural Networks
- While they are inspired by biology, neural networks are really _function approximators_
  - A sufficiently large neural network can approximate _any_ function =f(x)=
- Hypothetically, given enough data, a neural network can (kind of) solve any learning problem that has inputs and desired outputs
  - However, there are still lots of problems for which not enough labeled data exists to solve the problem using neural networks
  - And there are lots of problems for which other algorithms work better

* Neural Networks and Computer Vision
- Applying neural networks to computer vision problems has been very successful in the last 10 years
- We can make neural networks that take in an image and output the probability that the image is of a certain category for 1000 different categories (for the CIFAR-1000 dataset, as an example)
#+ATTR_HTML: :width 60%
[[https://www.tensorflow.org/images/AlexClassification.png]]

* Neural Networks and Computer Vision
- To process images, we replace the early layers of the neural network with special _convolutional layers_
- A convolutional layer is a set of M linear filters/kernels
  - Input: stack of N images (e.g. color image is a stack of 3 color channels)
  - Output: stack of M images
  - Each kernel is KxKxN in size (usually K=3 or 5)
  - Apply linear filtering/convolution using each kernel to create a 2D output image
  - Apply an activation function to every element of the output image
  - Then the output is the stack of M activation images
- The convolutional layers are followed by normal layers

* Neural Networks and Computer Vision
- Every element of every kernel is a learnable parameter
  - We can still take the derivative of the loss with respect to these kernel elements and update them just the same
- Example of how convolutional layers can build on one another
  - Conv layer 1 activates on things like edges
  - Conv layer 2 activates on things like eyes and noses
  - Conv layer 3 activates on parts of faces